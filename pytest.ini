[pytest]
# Test discovery patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = tests

# Minimum Python version
minversion = 6.0

# Command line options
addopts = 
    -ra
    -q
    --strict-markers
    --strict-config
    --cov=shared
    --cov=op1_large
    --cov=op2_lite
    --cov-branch
    --cov-report=term-missing:skip-covered
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-fail-under=80
    --benchmark-disable
    --tb=short
    --maxfail=1

# Custom markers
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    gpu: marks tests that require GPU hardware
    integration: marks integration tests
    benchmark: marks performance benchmark tests
    docker: marks tests requiring Docker
    unit: marks unit tests
    e2e: marks end-to-end tests

# Test output
console_output_style = progress

# Warnings
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore:.*unclosed.*:ResourceWarning

# Coverage settings
[coverage:run]
source = .
omit = 
    */tests/*
    */test_*
    */__pycache__/*
    */venv/*
    */env/*
    */.venv/*
    */.env/*
    */setup.py
    */conftest.py

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    def __str__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstract
    @abstractmethod

[coverage:html]
directory = htmlcov

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Benchmark settings
[benchmark]
min_rounds = 5
min_time = 0.000005
max_time = 1.0
calibration_precision = 10
warmup = yes
warmup_iterations = 100000
disable_gc = yes
sort = mean